#!/bin/bash


CURR_SHELL=$(. bin/retshell)
echo "$CURR_SHELL"

# Default configuration
pass_on_warn=0  # Default for warnings causing failures

# Function to display help
usage() {
    echo "Usage: $0 --profile AWS_PROFILE [--region-az REGION-AZ] [--pass-on-warn]"
    echo "       --region-az REGION-AZ   Specify the AWS region and availability zone (ie: us-west-2b)"
    echo "       --pass-on-warn          Allow warnings to pass without failure (default: false)"
    echo "       --profile  aws profile to use"
    echo " .     --config <path>       Path to the daylily-create-ephemeral-cluster config, default: ./.dayephmeral.env)"
}


# Check if script is sourced with no arguments
if [[ $# -eq 0 ]]; then
    usage
    exit 0
fi

if [ -z "$AWS_PROFILE" ]; then
    echo "❌ Error: AWS_PROFILE is not set."
    exit 1  # Exit the function with an error status
fi

CONFIG_FILE="config/daylily_ephemeral_cluster.yaml"

# Parse command-line arguments
while [[ $# -gt 0 ]]; do
    case "$1" in
        --region-az)
            region_az="$2"
            region="${region_az:0:${#region_az}-1}"
            shift 2
            ;;
        --pass-on-warn)
            pass_on_warn="1"
            shift
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        --profile)
            AWS_PROFILEIN="$2"
            shift 2
            ;;
        --config)
            CONFIG_FILE="$2"
            shift 2
            ;;
        *)
            echo "❌ Error: Unknown option: $1"
            usage
            exit 3
            ;;
    esac
done

if [[ -z "$AWS_PROFILE" ]]; then
    echo "❌ Error: --profile flag not set"
    exit 3  # Exit the function with an error status
fi

if [[ "$AWS_PROFILE" != "$AWS_PROFILEIN" ]]; then
    echo "❌ Error: AWS_PROFILE and --profile must match: $AWS_PROFILE and $AWS_PROFILEIN"
    exit 3  # Exit the function with an error status
fi

if [[ -z "$region_az" ]]; then
    echo "❌ Error: --region-az flag not set"
    exit 3  # Exit the function with an error status
fi

# Load the environment variables from .env file
if [ -f $CONFIG_FILE ]; then
    echo "Loading configuration from $CONFIG_FILE"
    CONFIG_BUDGET_EMAIL=$(yq -r '.ephemeral_cluster.config.budget_email' $CONFIG_FILE)
    CONFIG_ALLOWED_BUDGET_USERS=$(yq -r '.ephemeral_cluster.config.allowed_budget_users' $CONFIG_FILE)
    CONFIG_BUDGET_AMOUNT=$(yq -r '.ephemeral_cluster.config.budget_amount' $CONFIG_FILE)
    CONFIG_ENFORCE_BUDGET=$(yq -r '.ephemeral_cluster.config.enforce_budget' $CONFIG_FILE)
    CONFIG_DELETE_LOCAL_ROOT=$(yq -r '.ephemeral_cluster.config.delete_local_root' $CONFIG_FILE)
    CONFIG_AUTO_DELETE_FSX=$(yq -r '.ephemeral_cluster.config.auto_delete_fsx' $CONFIG_FILE)
    CONFIG_FSX_FS_SIZE=$(yq -r '.ephemeral_cluster.config.fsx_fs_size' $CONFIG_FILE)
    CONFIG_ENABLE_DETAILED_MONITORING=$(yq -r '.ephemeral_cluster.config.enable_detailed_monitoring' $CONFIG_FILE)
    CONFIG_CLUSTER_TEMPLATE_YAML=$(yq -r '.ephemeral_cluster.config.cluster_template_yaml' $CONFIG_FILE)
    CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY=$(yq -r '.ephemeral_cluster.config.spot_instance_allocation_strategy' $CONFIG_FILE)
    CONFIG_MAX_COUNT_8I=$(yq -r '.ephemeral_cluster.config.max_count_8I' $CONFIG_FILE)
    CONFIG_MAX_COUNT_128I=$(yq -r '.ephemeral_cluster.config.max_count_128I' $CONFIG_FILE)
    CONFIG_MAX_COUNT_192I=$(yq -r '.ephemeral_cluster.config.max_count_192I' $CONFIG_FILE)
    CONFIG_HEADNODE_INSTANCE_TYPE=$(yq -r '.ephemeral_cluster.config.headnode_instance_type' $CONFIG_FILE)
else
  echo "$CONFIG_FILE file not found!"
  sleep 1
fi  

echo "$CONFIG_FILE file VARS (if any):"
echo "CONFIG_BUDGET_EMAIL: $CONFIG_BUDGET_EMAIL"
echo "CONFIG_ALLOWED_BUDGET_USERS: $CONFIG_ALLOWED_BUDGET_USERS"
echo "CONFIG_BUDGET_AMOUNT: $CONFIG_BUDGET_AMOUNT"
echo "CONFIG_ENFORCE_BUDGET: $CONFIG_ENFORCE_BUDGET"
echo "CONFIG_DELETE_LOCAL_ROOT: $CONFIG_DELETE_LOCAL_ROOT"
echo "CONFIG_AUTO_DELETE_FSX: $CONFIG_AUTO_DELETE_FSX"
echo "CONFIG_FSX_FS_SIZE: $CONFIG_FSX_FS_SIZE"
echo "CONFIG_ENABLE_DETAILED_MONITORING: $CONFIG_ENABLE_DETAILED_MONITORING"
echo "CONFIG_CLUSTER_TEMPLATE_YAML: $CONFIG_CLUSTER_TEMPLATE_YAML"
echo "CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY: $CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY"
echo "CONFIG_MAX_COUNT_8I: $CONFIG_MAX_COUNT_8I"
echo "CONFIG_MAX_COUNT_128I: $CONFIG_MAX_COUNT_128I"
echo "CONFIG_MAX_COUNT_192I: $CONFIG_MAX_COUNT_192I"
echo "CONFIG_HEADNOD_INSTANCE_TYPE: $CONFIG_HEADNODE_INSTANCE_TYPE"
echo ""

echo "If you wish to override the above values, please edit the $CONFIG_FILE file appropriately. These defaults are set for a very low quota account, so you will want to boost the CONFIG_MAX_COUNT_*I values if you have higher spot quotas."

echo ""
echo "please confirm these values are correct and press Enter to continue, or any other key to exit."

read confirm "Press enter to continue, any other key to exit: " 
if [[ "$confirm" != "" ]]; then
    echo "Exiting..."
    exit 3
fi

if [[ -z "$CONFIG_MAX_COUNT_8I" ]]; then
    CONFIG_MAX_COUNT_8I=1
fi
if [[ -z "$CONFIG_MAX_COUNT_128I" ]]; then
    CONFIG_MAX_COUNT_128I=1
fi
if [[ -z "$CONFIG_MAX_COUNT_192I" ]]; then
    CONFIG_MAX_COUNT_192I=1
fi

# Extract the last character
az_char="${region_az: -1}"

# Check if the last character is a letter
if [[ "$az_char" =~ [a-zA-Z] ]]; then
    echo "The last character of --region-az ${region_az} '$az_char' is a letter."
else
    echo "❌ Error: The last character of --region-az ${region_az} '$az_char' is a NOT letter."
    exit 3  # Exit the function with an error status
fi

if [[ "$AWS_PROFILEIN" != "$AWS_PROFILE" ]]; then
    echo "❌ Error: AWS_PROFILE and --profile must match: $AWS_PROFILE and $AWS_PROFILEIN"
    exit 3  # Exit the function with an error status
fi

AWS_PROFILE=$AWS_PROFILE
echo "YOUR AWS_PROFILE IS NOW SET TO: $AWS_PROFILE"

# Function to handle warnings
handle_warning() {
    local message="$1"
    echo -e "WARNING: $message"
    echo "If appropriate, consider setting --pass-on-warn to continue without failure. Current setting: $pass_on_warn"
    if [[ "$pass_on_warn" != "1" ]]; then
        echo "Exiting due to warning."
        exit 3
    fi
}

validate_region() {
  echo "REGION:" $1 
}
echo "DEBUG: pass_on_warn after parsing: $pass_on_warn"

# Check if system packages are installed
./bin/check_prereq_sw.sh
if [ $? -ne 0 ]; then
    handle_warning "There were problems detected with pre-requisites, and the warnings bypassed. Run './bin/check_prereq_sw.sh' for more information ." 
    if [[ $? -ne 0 ]]; then
        echo "❌ Error: System package check failed, investigate or run again with or use --pass-on-warn."
        exit 3
    fi
fi

# Ensure Conda exists
conda --version &> /dev/null
if [[ $? -ne 0 ]]; then
    echo ">  > ❌ Error <  <"
    echo "Conda is not available in this shell (version >= 24.0.0)."
    echo "Please run the following command to install miniconda. *warning*, if you are using homebrew conda, things might get wobbly."
    echo ""
    echo "To install miniconda, run:"
    echo "    ./bin/install_miniconda # and once installed, open a new shell and run "
    exit 1
fi

# Check conda version is sufficent
# Required version
required_version="24.0.0"

# Get the current conda version
current_version=$(conda --version | awk '{print $2}')

# Compare versions
if [[ "$(printf '%s\n' "$required_version" "$current_version" | sort -V | head -n1)" != "$required_version" ]]; then
    echo "❌ Error: Conda version $current_version is less than the required version $required_version ."
    exit 3
fi

echo "Conda version $current_version meets the requirement of $required_version or higher."


# Check if the Conda environment DAYCLI is active
if [[ "$CONDA_DEFAULT_ENV" == "DAYCLI" ]]; then
    echo "The Conda environment DAYCLI is active, proceeding."
else
    echo "The Conda environment DAYCLI is not active or missing."
    echo ""
    echo "Please activate the DAYCLI environment by running:"
    echo "    conda activate DAYCLI"
    echo ""
    echo "If the environment does not exist, create it by running:"
    echo "    ./bin/init_daycli"
    exit 3
fi


# Activate or create the Daylily CLI conda environment
if conda env list | grep -q "^DAYCLI "; then
    echo "Conda environment 'DAYCLI' already exists. Activating it."
else
    echo "Creating 'DAYCLI' environment."
    source bin/init_daycli
    if [[ $? -ne 0 ]]; then
        echo "❌ Error: Failed to create the 'DAYCLI' environment. Exiting."
        exit 3
    fi
fi
conda activate DAYCLI

AWS_CLI_USER=$(aws sts get-caller-identity --region $region --profile $AWS_PROFILE --query "Arn" --output text | awk -F '/' '{print $2}')

# Ensure pcluster is installed
echo "Checking pcluster version..."
expected_pcluster_version="3.11.1"
pcluster_version=$(pcluster version | grep 'version' | cut -d '"' -f 4)
if [[ "$pcluster_version" != "$expected_pcluster_version" ]]; then
    handle_warning "Warning: Expected pcluster version $expected_pcluster_version, but found version $pcluster_version."
    if [[ $? -ne 0 ]]; then
        echo "❌ Error: pcluster version mis-match:  expected:$expected_pcluster_version , detected:$pcluster_version ."
        exit 3
    fi
fi

### AWS Configuration Setup
# Check AWS credentials
echo "Verifying AWS credentials..."
if ! aws sts get-caller-identity --region "$region" --profile $AWS_PROFILE  &> /dev/null; then
    echo "❌ Error: AWS credentials are invalid or do not have access to the AWS account in region $region."
    exit 3
else
    echo "✅  AWS credentials verified successfully."
fi

# Call the region validation function
validate_region "$region" || exit 3

AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text  --profile $AWS_PROFILE )

# Get AWS caller identity
caller_identity_arn=$(aws sts get-caller-identity --query 'Arn' --output text --region "$region"  --profile $AWS_PROFILE )


# Check if the policy is attached to the user
DY_POLICY_NAME="daylily-service-cluster-policy"

if aws iam list-user-policies --user-name "$AWS_CLI_USER" | jq -e --arg policy "$DY_POLICY_NAME" '.PolicyNames[] | select(. == $policy)' > /dev/null; then
    echo "Policy $DY_POLICY_NAME is attached to the user. Proceeding..."
else
    echo "WARNING: The policy '$DY_POLICY_NAME' is not attached to the user '$AWS_CLI_USER'."
    echo "Please see the README 'Inline Policies' section for instructions on attaching the policy."
    echo ""
    echo "Do you want to proceed without attaching the policy (maybe you rolled your own)?"
    echo "1) Proceed anyway"
    echo "2) Exit"

    # Print the prompt and then read the input
    echo -n "Enter your choice (1 or 2): "
    read CHOICE

    if [ "$CHOICE" -eq 1 ]; then
        echo "✅ Proceeding anyway..."
    elif [ "$CHOICE" -eq 2 ]; then
        echo "❌ Exiting."
        exit 3 2>/dev/null || exit 3
    else
        echo "❌ Invalid choice. Exiting."
        exit 3 2>/dev/null || exit 3
    fi
fi

# AWS Quota Check Function
check_quota() {
    local resource_name="$1"
    local quota_code="$2"
    local recommended_count="$3"
    local sccode="$4"
    
    echo "Checking quota for $resource_name..."
    quota=$(aws service-quotas get-service-quota --service-code $sccode --quota-code "$quota_code" --region "$region" --profile $AWS_PROFILE  2>/dev/null)

    if [[ $? -ne 0 ]]; then
        handle_warning "❌ Error: Unable to retrieve quota for $resource_name."
        exit 3
    fi

    quota_value=$(echo "$quota" | jq -r '.Quota.Value')


    # Calculate total vCPUs requested
    tot_vcpu=$(( (CONFIG_MAX_COUNT_8I * 8) + (CONFIG_MAX_COUNT_128I * 128) + (CONFIG_MAX_COUNT_192I * 192) ))

    
    # Check if the requested vCPUs exceed the quota
    if [[ "$quota_code" == "L-34B43A08" && "$tot_vcpu" -ge "$quota_value" ]]; then
        echo "Your requested instance types total vCPUs ($tot_vcpu) exceed the quota ($quota_value) for $quota_code in region $region."
        echo "This will cause the cluster to fail to allocate spot instances."
        echo "You must request a quota increase of at least $tot_vcpu or adjust downwards the instance type max in config/daylily_ephemeral_cluster.yaml."
        echo "It is not advised to skip this warning, but you may by pressing enter, all other keys will exis"

        read confirmq "Press enter to continue, any other key to exit: " 
        if [[ "$confirmq" != "" ]]; then
            echo "Exiting..."
            exit 3
        fi
        echo "There be dragons..."
    fi

    if (( $(echo "$quota_value < $recommended_count" | bc -l) )); then
        handle_warning "Warning: $resource_name quota $quota_code in $region is below the recommended $recommended_count. Current quota: $quota_value."
        if [[ $? -ne 0 ]]; then
            echo "❌ quota check failed"
            exit 3
        fi
    else
        echo "✅ $resource_name quota is sufficient: $quota_value."
    fi
}
echo ""

# Quota Checks for Key AWS Resources
echo "Performing AWS quota checks..."

# Dedicated Instances
check_quota "On Demand vCPU Max" "L-1216C47A" 20 ec2
if [[ $? -ne 0 ]]; then
    echo "On Demand vCPU Max quota L-1216C47A in $region MUST BE >= 20 <<< DO NOT SKIP THIS WARNING!!! request a quota incr."
    sleep 30
    exit 3
fi
echo ""

# Spot vCPU Max Quota 
check_quota "Spot vCPU Max" "L-34B43A08" 192 ec2
if [[ $? -ne 0 ]]; then
    echo "Spot vCPU Max quota L-34B43A08  in $region MUST BE >= 192 <<< DO NOT SKIP THIS WARNING!!! request a quota incr."
    sleep 30
    exit 3
fi
echo ""

# VPC Quota (Default: 5 per region)
check_quota "VPCs" "L-F678F1CE" 4 vpc
if [[ $? -ne 0 ]]; then
    exit 3
fi
echo ""

# Elastic IP Quota (Default: 5 per region)
check_quota "Elastic IPs" "L-0263D0A3" 4 ec2
if [[ $? -ne 0 ]]; then
    exit 3
fi
echo ""

# NAT Gateway Quota (Default: 5 per AZ)
check_quota "NAT Gateways" "L-FE5A380F" 4 vpc
if [[ $? -ne 0 ]]; then
    exit 3
fi
echo ""

# Internet Gateway Quota (Default: 5 per region)
check_quota "Internet Gateways" "L-A4707A72" 4 vpc
if [[ $? -ne 0 ]]; then
    exit 3
fi
echo ""



# Check for 'pcluster-omics-analysis' policy and create if necessary
echo "Checking for required IAM policy 'pcluster-omics-analysis'..."
policy_name="pcluster-omics-analysis"
policy_arn=$(aws iam list-policies --query "Policies[?PolicyName=='$policy_name'].Arn" --output text --region "$region"  --profile $AWS_PROFILE )
if [[ -z "$policy_arn" ]]; then
    echo "Creating IAM policy '$policy_name'..."
    policy_document='{
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": "iam:CreateServiceLinkedRole",
          "Resource": "*",
          "Condition": {
            "StringLike": {
              "iam:AWSServiceName": "spot.amazonaws.com"
            }
          }
        }
      ]
    }'
    aws iam create-policy --policy-name "$policy_name" --policy-document "$policy_document" --region "$region"  --profile $AWS_PROFILE 
fi

echo ""

## PEM File Check
# Fetch all key pairs in the given region
key_data=$(aws ec2 describe-key-pairs --region "$region" --query 'KeyPairs[*].[KeyName, KeyType]' --output text  --profile $AWS_PROFILE | grep omics)

echo "Keys in region $region:"
echo "$key_data"

export pem_file="na"
# Filter for keys with the required suffix
filtered_keys=()
while IFS=$'\t' read -r key_name key_type; do
    if [[ $key_type == "ed25519" ]]; then
        pem_file_f=$HOME/.ssh/"${key_name}.pem"
        pem_status="❌ pem - NOT FOUND"
        [[ -f "$pem_file_f" ]] && pem_status="✅ pem - FOUND"
        filtered_keys+=("$key_name|$key_type|$pem_status|$pem_file_f")
    fi
done <<< "$key_data"

# Present valid keys to the user
echo "Available ED25519 keys with matching PEM files:"
valid_keys=()
index=1
for key_info in "${filtered_keys[@]}"; do
    IFS='|' read -r key_name key_type pem_status pem_file <<< "$key_info"
    if [[ $pem_status == "✅ pem - FOUND" ]]; then
        valid_keys+=("$key_name")
        echo "[$index] Key: $key_name | Type: $key_type | PEM: $pem_status"
        ((index++))
    fi
done
echo ""

# Check if no valid keys were found
if [[ ${#valid_keys[@]} -eq 0 ]]; then
    echo "❌ No valid ED25519 keys with matching PEM files were found."
    echo "Please ensure the required keys are available in the $HOME/.ssh directory AND that the keypair name includes 'omics' in the name."
    exit 3
fi
# Present valid keys to the user using 'select'
echo "Select a valid ED25519 key with a matching PEM file:"
PS3="Enter the corresponding number: "
select key_info in "${filtered_keys[@]}"; do
    if [[ -n "$key_info" ]]; then
        # Extract the key name from the selected item
        selected_key=$(echo "$key_info" | awk -F'|' '{print $1}')
        echo "You selected: $selected_key"
        break
    else
        echo "Invalid selection. Please try again."
    fi
done

echo ""

# Proceed with further operations using the selected key
# Example: connect to an instance or perform other operations
pem_file=$HOME/.ssh/"${selected_key}.pem"

# Check if the PEM file exists
if [[ ! -e "$pem_file" ]]; then
    echo "❌ Error: PEM file $pem_file does not exist. Exiting."
    exit 1
fi

# Determine file permissions in a portable way
current_permissions=$(stat --format='%a' "$pem_file" 2>/dev/null || stat -f '%A' "$pem_file" 2>/dev/null)

if [[ -z "$current_permissions" ]]; then
    echo "❌ Error: Unable to determine permissions for $pem_file. Ensure 'stat' is available."
    exit 2
fi

# Check if the PEM file permissions are 400
if [[ "$current_permissions" -ne 400 ]]; then
    echo "❌ Error: The PEM file $pem_file does not have the required permissions of 400."
    echo "Please run: chmod 400 $pem_file"
    exit 3
fi

echo "The PEM file $pem_file has the correct permissions (400)."
echo "✅ Using key: $selected_key with PEM file $pem_file"

# Query available S3 buckets and present only those in the correct region
echo "Fetching S3 buckets matching 'omics-analysis' in $region..."
buckets=$(aws s3api list-buckets --profile $AWS_PROFILE --query "Buckets[].Name" --output text  --profile $AWS_PROFILE | tr '\t' '\n' | \
while read -r bucket; do \
  region=$(aws s3api get-bucket-location  --profile $AWS_PROFILE --bucket "$bucket" --query "LocationConstraint" --output text --profile $AWS_PROFILE ); \
  echo "$bucket ($region)" | grep "omics-analysis"; \
done)

matching_buckets=()
while IFS= read  bucket; do
    bucket_region=$(echo "$bucket" | awk '{print $NF}')

    # Handle 'None' as 'us-east-1'
    if [[ "$bucket_region" == "(None)" ]]; then
        bucket_region="(us-east-1)"
    fi

    if [[ "$bucket_region" == "($region)" ]]; then
        matching_buckets+=("$bucket")
    fi
done <<< "$buckets"

if [[ ${#matching_buckets[@]} -eq 0 ]]; then
    echo "❌ No matching buckets found in region $region."
    exit 3
fi

echo "Select a matching S3 bucket:"
select bucket_choice in "${matching_buckets[@]}"; do
    selected_bucket=$(echo "$bucket_choice" | awk '{print $1}')
    echo "✅ You selected: $selected_bucket"
    break
done

bucket=$(echo $bucket_choice | cut -f 1 -d " " )


# Check if the required folders exist in the bucket
check_s3_folder() {
    local bucket=$1
    local folder=$2

    if aws s3 ls "s3://$bucket/$folder/" --profile $AWS_PROFILE > /dev/null 2>&1; then
        echo "Folder s3://$bucket/$folder/ exists."
    else
        echo "❌ Error: Folder s3://$bucket/$folder/ does not exist."
        exit 1
    fi
}

echo "Validating required folders in bucket: $selected_bucket"
check_s3_folder "$bucket" "data" || exit 3
check_s3_folder "$bucket" "cluster_boot_config" || exit 3 


bucket_url="s3://$selected_bucket"
bucket_name=$bucket
echo "✅ All required folders exist in $bucket_url."

## TODO: add a check to confirim the bucket has the expected s3://%{bucket}/data and s3://%{bucket}/cluster_boot_config folders

echo ""

# Query for public and private subnets and ARN
echo "Checking subnets and ARN in the specified AZ: $region_az..."

public_subnets=$(aws ec2 describe-subnets \
  --query "Subnets[?AvailabilityZone=='$region_az'].{ID: SubnetId, Name: Tags[?Key=='Name']|[0].Value}" \
  --region "$region" --output text  --profile $AWS_PROFILE | grep "Public Subnet"
  )
  
private_subnets=$(aws ec2 describe-subnets \
  --query "Subnets[?AvailabilityZone=='$region_az'].{ID: SubnetId, Name: Tags[?Key=='Name']|[0].Value}" \
  --region "$region" --output text  --profile $AWS_PROFILE | grep "Private Subnet"
)

arn_count=$(aws iam list-policies --query 'Policies[?PolicyName==`pclusterTagsAndBudget`].Arn' --output text --region "$region"  --profile $AWS_PROFILE | wc -l)

if [[ -z "$public_subnets" && -z "$private_subnets" ]]; then
    echo "All required resources are missing. Running the initialization script..."
    res_prefix=$(echo "daylily-cs-$region_az" | sed -e 's/1/one/g' -e 's/2/two/g' -e 's/3/three/g' -e 's/4/four/g')

    bin/init_cloudstackformation.sh ./config/day_cluster/pcluster_env.yml "$res_prefix" "$region_az" "$region" $AWS_PROFILE
elif [[ -z "$public_subnets" || -z "$private_subnets"  ]]; then
    echo "❌ Error: Incomplete setup. Ensure public and private subnets and the required ARN are available.  You might try running : bin/init_cloudstackformation.sh ./config/day_cluster/pcluster_env.yml $res_prefix $region_az $region $AWS_PROFILE"
    exit 1
else
    echo "✅ All required resources are available."
fi
echo ""

echo "✅ Setup complete. Proceeding with the remaining steps..."

echo ""
echo ""

# Select public and private subnets
public_subnets_new=$(aws ec2 describe-subnets --query "Subnets[*].[SubnetId, Tags[?Key=='Name'].Value | [0], AvailabilityZone]" --region "$region" --output text  --profile $AWS_PROFILE | grep "Public Subnet" | grep $region_az)
echo "Select a Public Subnet (todo: move to selecting VPC first, then filtering options w/in VPC for pub/priv subs):"
public_subnet_choices=()
while read -r subnet_id subnet_name; do
    public_subnet_choices+=("$subnet_name ($subnet_id)")
done <<< "$public_subnets_new"
echo ""

select public_subnet_choice in "${public_subnet_choices[@]}"; do
    public_subnet=$(echo "$public_subnet_choice" | sed -n 's/.*(\(.*\)).*/\1/p')
    echo "✅ You selected Public Subnet: $public_subnet"
    break
done
echo ""

echo "Select a Private Subnet (in same vpc as public):"
private_subnets_new=$(aws ec2 describe-subnets --query "Subnets[*].[SubnetId, Tags[?Key=='Name'].Value | [0], AvailabilityZone]" --region "$region" --output text  --profile $AWS_PROFILE | grep "Private Subnet" | grep $region_az)
private_subnet_choices=()
while read -r subnet_id subnet_name; do
    private_subnet_choices+=("$subnet_name ($subnet_id)")
done <<< "$private_subnets_new"
echo ""

select private_subnet_choice in "${private_subnet_choices[@]}"; do
    private_subnet=$(echo "$private_subnet_choice" | sed -n 's/.*(\(.*\)).*/\1/p')
    echo "✅ You selected Private Subnet: $private_subnet"
    break
done


echo ""
# Select an IAM policy ARN for 'pclusterTagsAndBudget'
policy_arns=($(aws iam list-policies --query 'Policies[?PolicyName==`pclusterTagsAndBudget`].Arn' --output text --region "$region" --profile $AWS_PROFILE ))
echo "Select an IAM policy ARN for 'pclusterTagsAndBudget':"
select arn_policy_id in "${policy_arns[@]}"; do
    echo "✅ You selected: $arn_policy_id"
    break
done
echo ""

if [[ -z "$arn_policy_id" ]]; then
    echo "❌ Error: No IAM policy ARN selected. Exiting."
    exit 3
fi

echo ""

# Function to validate cluster name
validate_cluster_name() {
    if [[ ! "$1" =~ ^[a-zA-Z0-9\-]+$ ]] || [[ ${#1} -gt 25 ]]; then
        return 1
    else
        return 0
    fi
}

# Prompt user for cluster name in a loop until valid input is given
while true; do
    read -rp "Enter the name for your cluster (alphanumeric and '-', max 25 chars): " cluster_name

    if validate_cluster_name "$cluster_name"; then
        echo "✅ Cluster name accepted: $cluster_name"
        break
    else
        echo "❌ Error: Invalid cluster name."
        echo "   ➜ The name must be alphanumeric, may include '-', and be 25 characters or fewer."
    fi
done

# Default Budget Check

# Function to prompt for email
budget_email=""
if [[ -n "$CONFIG_BUDGET_EMAIL" && "$CONFIG_BUDGET_EMAIL" != "ENTEREMAIL" ]]; then
    budget_email="$CONFIG_BUDGET_EMAIL"
else
    prompt_for_email() {
        while true; do
            echo ""
            read -rp "Enter an email address to send budget alerts to: " budget_email
            # Regex pattern for basic email validation
            if [[ -z "$budget_email" ]]; then
                echo "Email cannot be empty. Please try again."
            elif [[ "$budget_email" =~ ^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$ ]]; then
                echo "Valid email entered: $budget_email"
                break
            else
                echo "Invalid email format. Please use string@string.string format."
            fi
        done
    }

    prompt_for_email
fi

echo ""
# CLuster Budget Check
global_budget_name="daylily-global"
echo "Checking if the $global_budget_name budget exists..."

# Query AWS for the budget
global_budget_exists=$(aws budgets describe-budgets \
    --query "Budgets[?BudgetName=='$global_budget_name'] | [0].BudgetName" \
    --output text --region "$region" --account-id "$AWS_ACCOUNT_ID"  --profile $AWS_PROFILE )

# Check if the output is empty
if [[ -z "$global_budget_exists" || "$global_budget_exists" == "None" ]]; then
    echo "Budget '$global_budget_name' not found."

    echo -n "Enter csv string of allowed user names for budget (ubuntu is allowed for all budgets):"
    read gallowed_users

    echo -n "Enter a budget amount (default: 300): "
    read gamount
    gamount=${gamount:-200}

    echo "Creating the budget..."
    echo "bin/create_budget.sh -p $global_budget_name -r $region -t 25,50,75,99 -e $budget_email -a $gamount -c $cluster_name -z $region_az -b $bucket_url  -u $gallowed_users "
    bin/create_budget.sh -p $global_budget_name -r $region -t 25,50,75,99 -e "$budget_email" -a "$gamount" -c $cluster_name -z $region_az -b $bucket_url  -u "$gallowed_users "

    if [[ $? -ne 0 ]]; then
        echo "❌ Error: Failed to create the budget. Exiting."
        exit 3
    else
        echo "✅  Budget '$global_budget_name' created successfully."
    fi
else
    echo "✅ Default budget '$global_budget_name' exists. Proceeding"
fi



# CLuster Budget Check
echo "Checking if the 'daylily-omics-analysis-${region_az}' budget exists..."
budget_name="da-${region_az}-${cluster_name}"

# Query AWS for the budget
budget_exists=$(aws budgets describe-budgets \
    --query "Budgets[?BudgetName=='$budget_name'] | [0].BudgetName" \
    --output text --region "$region" --account-id "$AWS_ACCOUNT_ID"  --profile $AWS_PROFILE )

# Check if the output is empty
if [[ -z "$budget_exists" || "$budget_exists" == "None" ]]; then
    echo "Budget '$budget_name' not found."

    allowed_users=""
    if [[ -n "$CONFIG_ALLOWED_BUDGET_USERS" ]]; then
        allowed_users="$CONFIG_ALLOWED_BUDGET_USERS"
    else        
        echo -n "Enter csv string of allowed user names for budget (ubuntu is allowed for all budgets):"
        read allowed_users
    fi

    amount="200"
    if [[ -n "$CONFIG_BUDGET_AMOUNT" ]]; then
        amount="$CONFIG_BUDGET_AMOUNT"
    else
        echo -n "Enter a budget amount (default: 200): "
        read amount
        amount=${gamount:-200}
    fi

    echo "Creating the budget..."
    echo "bin/create_budget.sh -p $budget_name -r $region -t 75 -e $budget_email -a $amount -c $cluster_name -z $region_az -b $bucket_url  -u $allowed_users "
    bin/create_budget.sh -p $budget_name -r $region -t 75 -e "$budget_email" -a "$amount" -c $cluster_name -z $region_az -b $bucket_url  -u "$allowed_users "

    if [[ $? -ne 0 ]]; then
        echo "❌ Error: Failed to create the budget. Exiting."
        exit 3
    else
        echo "✅ Budget '$budget_name' created successfully."
    fi
else
    echo "✅ Default budget '$budget_name' exists. Proceeding"
fi
echo ""

# Budget enforcement
enforce_budget_opt="false"
if [[ -n "$CONFIG_ENFORCE_BUDGET" ]]; then
    enforce_budget_opt="$CONFIG_ENFORCE_BUDGET"
else
    echo "Enforce budget for the cluster? (1) No (2) Yes:"
    echo "if enforced, new jobs will be blocked if the budget is exceeded, but the cluster will continue to run until you shut it down."
    select enforce_budget in "No" "Yes"; do
        if [[ "$enforce_budget" == "Yes" ]]; then
            enforce_budget_opt="enforce"
        else
            enforce_budget_opt="skip"
        fi
        break
    done
    echo ""
fi

# Cluster config file input
cluster_yaml=""
if [[ -n "$CONFIG_CLUSTER_TEMPLATE_YAML" ]]; then
    cluster_yaml="$CONFIG_CLUSTER_TEMPLATE_YAML"
else

    echo -n "Enter the path to the Daylily cluster config YAML file [press Enter to use default 'config/day_cluster/prod_cluster.yaml']: "
    read cluster_yaml

    if [[ -z "$cluster_yaml" ]]; then
        cluster_yaml="config/day_cluster/prod_cluster.yaml"
    fi    
fi
if [[ ! -f "$cluster_yaml" ]]; then
        echo "❌ Error: YAML file '$cluster_yaml' does not exist."
        exit 3
    fi 
echo "✅ Using cluster template yaml: $cluster_yaml"

echo ""

# XMR Mining Setup
# not reliable yet
xmr_pool_url=na
xmr_wallet=na
enable_xmr=0
#echo "Enable XMR mining with idle compute? (1) No (2) Yes:"
#select enable_xmr in "No" "Yes"; do
#    if [[ "$enable_xmr" == "Yes" ]]; then
#        echo -n "Specify a mining pool URL (default=pool.supportxmr.com:3333): "
#        read xmr_pool_url
#        [[ -z "$xmr_pool_url" ]] && xmr_pool_url="pool.supportxmr.com:3333"
#
#        echo -n "Specify a destination wallet (default wallet will donate coins to daylily development): "
#        read xmr_wallet
#        [[ -z "$xmr_wallet" ]] && xmr_wallet="42s1tbj3qp6T2QBw9BzYxxRn1e9afiZhcRr8yoe2QYLn5ZG6Fk9XzEh1719moDeUgY6tReaJDF464ZhbEyg4cXMYNRXJve2"
#
#        if ! nc -z $(echo "$xmr_pool_url" | cut -d: -f1) $(echo "$xmr_pool_url" | cut -d: -f2); then
#            handle_warning "Cannot reach the mining pool URL: $xmr_pool_url"
#        else
#            echo "Mining pool URL is reachable."
#        fi
#    else
#        enable_xmr="0"
#    fi
#    break
#done
echo ""


echo "Choose the headnode instance type (tested with r7i.2xlarge & should be of the same family to be safe):"

if [[ -n "$CONFIG_HEADNODE_INSTANCE_TYPE" ]]; then
    sel_headnode_type="$CONFIG_HEADNODE_INSTANCE_TYPE"
else
    headnode_options="r7i.2xlarge r7i.4xlarge r7i.8xlarge r7i.16xlarge"
    # Define select loop
    select headnode_type in $headnode_options; do
        sel_headnode_type=$(echo $headnode_type | awk '{print $1}')
        echo "You selected headnode instance type: $sel_headnode_type"
        break
    done
    echo "Headnode instance type: $sel_headnode_type"
    echo ""
fi

echo ""
echo "Choose the FSX Lustre File System Size (tested with 4800):"

sel_fsx_size="4800"
if [[ -n "$CONFIG_FSX_FS_SIZE" ]]; then
    sel_fsx_size="$CONFIG_FSX_FS_SIZE"
else
    fsx_options="4800 7200"
    # Define select loop
    select fsx_size in $fsx_options; do
        sel_fsx_size=$(echo $fsx_size | awk '{print $1}')
        echo "You selected FSX Lustre File System Size: $sel_fsx_size"
        break
    done
    echo "FSX Lustre File System Size: $sel_fsx_size"
    echo ""
fi
echo "✅ FSX Lustre File System Size: $sel_fsx_size"
echo ""

# Enable detailed monitoring
act_detailed_monitoring=false
if [[ -n "$CONFIG_ENABLE_DETAILED_MONITORING" ]]; then
    if [[ "$CONFIG_ENABLE_DETAILED_MONITORING" == "true" ]]; then
        act_detailed_monitoring="true"
    elif [[ "$CONFIG_ENABLE_DETAILED_MONITORING" == "false" ]]; then
        act_detailed_monitoring="false"
    else
        echo "❌ Error: Invalid value for CONFIG_DETAILED_MONITORING. Expected 'true' or 'false'."
        exit 3
    fi
else
    echo "Enable detailed monitoring (yes == incurs addl cost)? (1) No (2) Yes:"
    det_mon_options="No Yes"
    select detailed_monitoring in $det_mon_options; do
        sel_detailed_monitoring=$(echo $detailed_monitoring | awk '{print $1}')
        echo "You selected detailed monitoring: $sel_detailed_monitoring"
        if [[ "$act_detailed_monitoring" == "Yes" ]]; then
            act_detailed_monitoring="true"
        else
            act_detailed_monitoring="false"
        fi
        break
    done
fi
echo "✅ Detailed monitoring enabled?: $act_detailed_monitoring"
echo ""

# Prepare configuration
mkdir -p $HOME/.config/daylily
target_conf=$HOME/.config/daylily/${cluster_name}_cluster.yaml.init
target_conf_fin=$HOME/.config/daylily/${cluster_name}_cluster.yaml
regsub_vals=$HOME/.config/daylily/${cluster_name}_cluster_init_vals.txt

cp "$cluster_yaml" "$target_conf"
pem_name=$(basename "$pem_file" | cut -d '.' -f 1)


# capture 'true' or 'false' for delete_local_root
# if CONFIG_DELETE_LOCAL_ROOT is set, use that value
delete_local_root=true
if [[ -n "$CONFIG_DELETE_LOCAL_ROOT" ]]; then
    if [[ "$CONFIG_DELETE_LOCAL_ROOT" == "true" ]]; then
        delete_local_root="true"
    elif [[ "$CONFIG_DELETE_LOCAL_ROOT" == "false" ]]; then
        delete_local_root="false"
    else
        echo "❌ Error: Invalid value for CONFIG_DELETE_LOCAL_ROOT. Expected 'true' or 'false'."
        exit 3
    fi
else

    echo "Delete local root volume on termination? (1) No (2) Yes:"

    delete_local_root="true"
    if [[ -n "$CONFIG_DELETE_LOCAL_ROOT" ]]; then
        if [[ "$CONFIG_DELETE_LOCAL_ROOT" == "true" ]]; then
            delete_local_root="true"
        elif [[ "$CONFIG_DELETE_LOCAL_ROOT" == "false" ]]; then
            delete_local_root="false"
        else
            echo "❌ Error: Invalid value for CONFIG_DELETE_LOCAL_ROOT. Expected 'true' or 'false'."
            exit 3
        fi
    else
        select delete_local_root in "No" "Yes"; do
            if [[ "$delete_local_root" == "Yes" ]]; then
                delete_local_root="true"
            else
                delete_local_root="false"
            fi
            break
        done
    fi
fi
echo "✅ Delete local root volume on termination?: $delete_local_root"

# Retailn or delete the FSx Lustre file system
save_fsx="Delete"
if [[ -n "$CONFIG_AUTO_DELETE_FSX" ]]; then
    if [[ "$CONFIG_AUTO_DELETE_FSX" == "Retain" ]]; then
        save_fsx="Retain"
    elif [[ "$CONFIG_AUTO_DELETE_FSX" == "Delete" ]]; then
        save_fsx="Delete"
    else
        echo "❌ Error: Invalid value for CONFIG_AUTO_DELETE_FSX. Expected 'Retain' or 'Delete'."
        exit 3
    fi
else
    echo "Retain or delete the FSx Lustre file system on cluster [update|termination]? (1) Retain (2) Delete:"
   
    echo "[Retain|Delete] FSx Lustre file system on custer [update|termination]? (1) Retain (2) Delete:"
    select save_fsx in "Retain" "Delete"; do
        if [[ "$save_fsx" == "Delete" ]]; then
            save_fsx="Delete"
        else
            save_fsx="Retain"
        fi
        break
    done
fi
echo "✅ Retain or delete the FSx Lustre file system on cluster [update|termination]?: $save_fsx"
echo ""

allocation_strategy=""
if [[ -n "$CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY" ]]; then
    if [[ "$CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY" == "price-capacity-optimized" || "$CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY" == "capacity-optimized" || "$CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY" == "lowest-price" ]]; then
        allocation_strategy="$CONFIG_SPOT_INSTANCE_ALLOCATION_STRATEGY"
    else
        echo "❌ Error: Invalid value for CONFIG_ALLOCATION_STRATEGY. Expected 'price-capacity-optimized', 'capacity-optimized', or 'lowest-price'."
        exit 3
    fi
else

    # Loop until we get a valid selection or user presses Enter
    while true; do
    echo "Select A Spot Instance Allocation Strategy:"
    echo "1) price-capacity-optimized (default, balance of lowest-cost + capacity optimized placement)"
    echo "2) capacity-optimized (more expensive, fewer disruptions)"
    echo "3) lowest-price (potentially more disruptions)"
    echo -n "Enter selection [1]: "
    read user_choice

    case "$user_choice" in
        ""|1)
        # Default or user entered 1
        allocation_strategy="price-capacity-optimized"
        break
        ;;
        2)
        allocation_strategy="capacity-optimized"
        break
        ;;
        3)
        allocation_strategy="lowest-price"
        break
        ;;
        *)
        echo "Invalid selection. Please try again."
        echo
        ;;
    esac
    done
fi

echo "✅ You selected the allocation strategy: $allocation_strategy"
echo ""

git_deets=$(bin/get_git_deets.sh)

# Write variables to config
cat <<EOF > $regsub_vals
REGSUB_REGION=$region
REGSUB_PUB_SUBNET=$public_subnet
REGSUB_KEYNAME=$pem_name
REGSUB_S3_BUCKET_INIT=$bucket_url
REGSUB_S3_BUCKET_NAME=$bucket_name
REGSUB_S3_IAM_POLICY=$arn_policy_id
REGSUB_PRIVATE_SUBNET=$private_subnet
REGSUB_S3_BUCKET_REF=$bucket_url
REGSUB_XMR_MINE=$enable_xmr
REGSUB_XMR_POOL_URL=$xmr_pool_url
REGSUB_XMR_WALLET=$xmr_wallet
REGSUB_FSX_SIZE=$sel_fsx_size
REGSUB_DETAILED_MONITORING=$act_detailed_monitoring
REGSUB_CLUSTER_NAME=$cluster_name
REGSUB_USERNAME=${USER}-${AWS_CLI_USER}
REGSUB_PROJECT=$budget_name
REGSUB_DELETE_LOCAL_ROOT=$delete_local_root
REGSUB_SAVE_FSX=$save_fsx
REGSUB_ENFORCE_BUDGET=$enforce_budget_opt
REGSUB_AWS_ACCOUNT_ID=aws_profile-$AWS_PROFILE
REGSUB_ALLOCATION_STRATEGY=$allocation_strategy
REGSUB_DAYLILY_GIT_DEETS=$git_deets
REGSUB_MAX_COUNT_8I=$CONFIG_MAX_COUNT_8I
REGSUB_MAX_COUNT_128I=$CONFIG_MAX_COUNT_128I
REGSUB_MAX_COUNT_192I=$CONFIG_MAX_COUNT_192I
REGSUB_HEADNODE_INSTANCE_TYPE=$sel_headnode_type
EOF

echo ""

bash bin/other/regsub_yaml.sh $regsub_vals $target_conf
echo ""

echo "Calculating max spot bid prices per partition resource group..."
echo ""

python bin/calcuate_spotprice_for_cluster_yaml.py -i $target_conf -o $target_conf_fin --az $region_az --profile $AWS_PROFILE -b 4.14
echo ""

# Check the exit status of the previous command
if [[ $? -ne 0 ]]; then
    echo "❌ Error: Failed to calculate spot bid prices."
    echo "This is likely due to a policy/permissions issue in AWS."
    echo "Please refer to the quickstart guide for more information on required policies."
    exit 3  # Use 'exit 3' if outside a function or script
fi
echo "✅ Spot bid prices calculated successfully."

# Dry run cluster creation
echo "Running a cluster creation dry run..."
echo ""

json_response=$(pcluster create-cluster -n "$cluster_name" -c "$target_conf_fin" --dryrun true --region "$region"  )

message=$(echo "$json_response" | jq -r '.message')
echo ""

# Validate the message
if [[ "$message" == "Request would have succeeded, but DryRun flag is set." ]]; then
    echo "✅ Dry run successful. Proceeding with cluster creation."
elif [[ "$DAY_BREAK" == "1" ]]; then
    echo "DAY_BREAK == '1'.  Exiting without creating the cluster."
    exit 0
else
    echo "❌ Error: Dry run failed (  pcluster create-cluster -n $cluster_name -c $target_conf_fin --dryrun true --region $region   ). Exiting."
    exit 3
fi
echo ""

# Create the cluster
echo "Creating the cluster $cluster_name in region $region"
echo ""

pcluster create-cluster -n "$cluster_name" -c "$target_conf_fin" --region "$region"
echo ""

# Monitor cluster creation
echo "Monitoring cluster creation... this may take 15-60 minutes."
python bin/helpers/watch_cluster_status.py "$region"
echo ""

echo "✅ The cluster creation is complete, configure the head node by running 'source ./bin/daylily-cfg-headnode $pem_file $region $AWS_PROFILE' ."
echo "....trying this now!"
echo ""

sleep 2
source ./bin/daylily-cfg-headnode $pem_file $region $AWS_PROFILE
echo ""

echo "✅ ✅ ✅ ....fin! "
